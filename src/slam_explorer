#! /usr/bin/env python
import random

import rospy
from nav_msgs.msg import OccupancyGrid, Odometry
import numpy as np
import pandas as pd  # for saving the map to csv
import actionlib  # lib for placing the goal and robot autonomously navigating there
from move_base_msgs.msg import MoveBaseAction, MoveBaseGoal
from geometry_msgs.msg import Transform, TransformStamped, Vector3, Quaternion, Pose, Point
import tf2_ros  # lib for translating and rotating the frames
from random import randint
import copy
from math import sqrt
import skimage
import cv2
from visualization_msgs.msg import Marker  # for custom markers in RViz
from std_msgs.msg import Header, ColorRGBA  # for custom markers in RViz


# datatype for storing the cluster
class Cluster:

    def __init__(self, starting_point: dict, map_id: str, cluster_id: int, has_walls_inside_flag: bool = False):
        self.starting_point = starting_point  # starting point from which cluster is being searched further
        self.list_of_cells = np.asarray([[], []], dtype=int)  # list of cells of cluster
        self.map_id = map_id  # id of the map, on which clustering is conducted
        self.cluster_id = cluster_id  # enumerator of the cluster
        self.number_of_elements: int = 0  # number of cells in cluster
        self.cluster_centroid = {"j": None, "i": None}  # centroid of the cluster

        # Appending starting point to the cluster
        self.list_of_cells = np.concatenate((self.list_of_cells, np.asarray([[starting_point["j"]],
                                                                             [starting_point["i"]]])), axis=1)
        self.list_of_cells.astype(int, copy=False)

        # Flag if cluster has walls inside itself
        self.has_walls_inside_flag = has_walls_inside_flag

    def calculate_number_of_elements(self):
        self.number_of_elements = self.list_of_cells.shape[1]

    def calculate_centroid(self):
        # calculate the average coordinate:

        sum_coord_i = 0
        sum_coord_j = 0

        for cell in range(self.number_of_elements):
            sum_coord_j += self.list_of_cells[0][cell]
            sum_coord_i += self.list_of_cells[1][cell]

        self.cluster_centroid["i"] = int(sum_coord_i / self.number_of_elements)
        self.cluster_centroid["j"] = int(sum_coord_j / self.number_of_elements)

    def add_pixel(self, j, i):

        # Appending pixel to the cluster
        self.list_of_cells = np.concatenate((self.list_of_cells, np.asarray([[j], [i]])), axis=1)
        self.list_of_cells.astype(int, copy=False)


# Yamauchi's frontier detection method implemented in the class
class DFDdetectorClass:

    def __init__(self, min_size_frontier: float, percentage_cutoff: float):

        self.min_size_frontier = min_size_frontier  # minimum size of the frontier

        if percentage_cutoff > 1 or percentage_cutoff < 0:
            raise ValueError("DFD Error: The value of percentage cutoff should be between 0 and 1!")

        self.map_resolution: float = 0  # map resolution to calculate min_number_of_elements
        self.min_num_of_elements: int = 0  # will be calculated later

        self.percentage_cutoff = percentage_cutoff  # specifying how much top percentage
        # of gradient to left (0.3 = 70 %)

        self.idx = 1  # global index

        self.safe_boundary_between_goal_and_walls = 1   # [cells]

        self.raw_map_data_numpy_reshape = np.zeros((0, 0))   # global map for the class

    def map_gradient(self):
        map_I_copy = copy.deepcopy(self.raw_map_data_numpy_reshape)

        # initializing gradient magnitude of the map
        nmap_mag = np.zeros((map_I_copy.shape[0], map_I_copy.shape[1]), dtype="uint16")

        map_I_copy = map_I_copy.astype(np.int16)
        # assigning uint8 data type to the map, so value "-1" -> 255 and the biggest gradient is between -1:
        # not known and 100: occupied

        # changing values, so i'll get the biggest gradient between free cells: 0 and unknown: -1
        map_I_copy = np.where(map_I_copy == 100, 50, map_I_copy)  # Known Occupied: 100 -> 50
        map_I_copy = np.where(map_I_copy == -1, 100, map_I_copy)  # Unknown: -1 -> 100

        # Sobel kernel
        Gx = np.asarray([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]], dtype=np.int16)
        Gy = np.asarray([[-1, -2, -1], [0, 0, 0], [1, 2, 1]], dtype=np.int16)

        # Convoluting over whole map with mask, except 1 pixel border
        for j in range(1, map_I_copy.shape[0] - 2):
            for i in range(1, map_I_copy.shape[1] - 2):
                submap = map_I_copy[j - 1: j + 2, i - 1: i + 2]  # submap 3x3 pixels

                ncell_I_x = (submap * Gx).sum()  # element-wise multiplying and getting sum of all elements
                ncell_I_y = (submap * Gy).sum()  # element-wise multiplying and getting sum of all elements

                nmap_mag[j][i] = sqrt(
                    ncell_I_x ** 2 + ncell_I_y ** 2)  # get magnitude of gradient (we don't need theta)

        # Filtering out: leaving only the biggest gradient:
        max_gradient = np.amax(nmap_mag)  # get max value of gradient

        nmap_mag = np.where(nmap_mag < self.percentage_cutoff * max_gradient, 0, nmap_mag)  # filter out all cells,
        # except ones with
        # the highest gradient
        # (top 90%)

        nmap_mag = np.where(nmap_mag >= self.percentage_cutoff * max_gradient, 255, nmap_mag)  # make top highest
        # gradient:
        # 255, due to dtype
        # - highest
        # value (and for viz)

        nmap_mag = nmap_mag.astype(np.uint8)  # assing uint8 type to gradient map, because values are either 0 or 255

        return nmap_mag

    # Implements "Connected-Component Labeling" of binary image for clustering
    def clustering(self, nmap_mag, robot_position):

        cluster_list: list = []  # creating list, which will store all cluster objects
        nmap_mag_copy = copy.deepcopy(nmap_mag)  # making copy of magnitude map, to be able to delete pixels from it

        labeled_nmap_mag_copy = skimage.measure.label(nmap_mag_copy)    # CCL implemented labeling (returns ndarray:int)

        n_clusters = np.amax(labeled_nmap_mag_copy)     # number of clusters (0-th cluster is background)

        # DEBUG

        # cv2.namedWindow('CLUSTER ' + str(n_clusters), cv2.WINDOW_NORMAL)  # new window, named 'win_name'
        # cv2.imshow('CLUSTER ' + str(n_clusters), nmap_mag_copy)  # show image on window 'win_name' made of numpy.ndarray
        # cv2.resizeWindow('CLUSTER ' + str(n_clusters), 1600, 900)  # resizing window on my resolution
        #
        # cv2.waitKey(0)  # wait for key pressing
        # cv2.destroyAllWindows()  # close all windows

        # DEBUG END

        for i_cluster in range(1, n_clusters + 1):

            cluster_indices = np.where(labeled_nmap_mag_copy == i_cluster)

            starting_point = {"j": cluster_indices[0][0], "i": cluster_indices[1][0]}

            # checking if there is a wall in the cluster
            if np.any(self.raw_map_data_numpy_reshape[cluster_indices]) == 100:

                # doesn't add cluster to cluster list (deleting the cluster from nmap_mag_copy for visualisation)
                nmap_mag_copy[cluster_indices] = 0

            else:

                # initialising new cluster
                new_cluster = Cluster(starting_point, 'nmap_mag', i_cluster)

                # adding all cells to cluster
                for pixel in range(1, len(cluster_indices[0])):

                    new_cluster.add_pixel(cluster_indices[0][pixel], cluster_indices[1][pixel])

                new_cluster.calculate_number_of_elements()

                # if cluster is bigger than cluster_min_size -> calculate its centroid
                if new_cluster.number_of_elements > self.min_num_of_elements:

                    new_cluster.calculate_centroid()

                    cluster_list.append(copy.deepcopy(new_cluster))  # appending cluster to the cluster list

                # (deleting the cluster from nmap_mag_copy for visualisation)

                # DEBUG

                # if new_cluster.cluster_centroid["j"]:
                #     nmap_mag_copy[new_cluster.cluster_centroid["j"]][new_cluster.cluster_centroid["i"]] = 120
                #
                # cv2.namedWindow('CLUSTER '+str(i_cluster), cv2.WINDOW_NORMAL)  # new window, named 'win_name'
                # cv2.imshow('CLUSTER '+str(i_cluster), nmap_mag_copy)  # show image on window 'win_name' made of numpy.ndarray
                # cv2.resizeWindow('CLUSTER '+str(i_cluster), 1600, 900)  # resizing window on my resolution
                #
                # cv2.waitKey(0)  # wait for key pressing
                # cv2.destroyAllWindows()  # close all windows

                # DEBUG END

                # (deleting the cluster and its centroid from nmap_mag_copy for visualisation)
                nmap_mag_copy[cluster_indices] = 0

                if new_cluster.cluster_centroid["j"]:
                    nmap_mag_copy[new_cluster.cluster_centroid["j"]][new_cluster.cluster_centroid["i"]] = 0

        return cluster_list

    def frontier_detection_DFD(self, raw_map_data_numpy_reshape: np.ndarray,
                               robot_position_pix,
                               map_resolution: float, previous_map_reshape) -> dict:

        self.raw_map_data_numpy_reshape = raw_map_data_numpy_reshape

        self.map_resolution = map_resolution
        self.min_num_of_elements = int(self.min_size_frontier / self.map_resolution)

        gradient = self.map_gradient()
        cluster_list = self.clustering(gradient, robot_position_pix)

        distance_from_centroid = []

        # DEBUG

        # print("| CLUSTER ID | CENTROID  | DIST2CENT | ROBOT POS |  \n")
        # print("__________________________________________________  \n")

        # END OF DEBUG

        # computing distances to centroid for all clusters
        for cluster in cluster_list:

            c_j = cluster.cluster_centroid["j"]
            c_i = cluster.cluster_centroid["i"]
            centroid_neighbourhood = raw_map_data_numpy_reshape[c_j - self.safe_boundary_between_goal_and_walls:
                                                                c_j + self.safe_boundary_between_goal_and_walls,
                                                                c_i - self.safe_boundary_between_goal_and_walls:
                                                                c_i + self.safe_boundary_between_goal_and_walls]

            # Check if cluster centroid or any of its neighbours are in the wall(if in the wall -> remove,
            #                                                                   else -> calculate centroid):
            if np.all(centroid_neighbourhood != 100):
                # print("There is NO wall around!!!")
                distance_from_centroid.append(sqrt((robot_position_pix["i"] - cluster.cluster_centroid["i"]) ** 2 +
                                                   (robot_position_pix["j"] - cluster.cluster_centroid["j"]) ** 2))

                # DEBUG

                # print("|   ", cluster.cluster_id, "      |   [", [c_j, c_i], "]    |   ", distance_from_centroid[-1],
                #       "    |   ", [robot_position_pix["j"], robot_position_pix["i"]], "      |  \n")
                # print("______________________________________  \n")

                # END OF DEBUG

            else:
                # print("There is wall around!!!")
                cluster_list.remove(cluster)

        # sorting dict from min distance_from_centroid to max

        distance_from_centroid_sorted = copy.deepcopy(distance_from_centroid)
        distance_from_centroid_sorted.sort()

        # condition to go to other frontiers (not the closest one) if map doesn't change,
        # if map changes, go to the closest one

        if np.all(raw_map_data_numpy_reshape == previous_map_reshape):

            curr_distance = distance_from_centroid_sorted[self.idx]

            curr_distance_idx = distance_from_centroid.index(curr_distance)

            goal_coords_pix = {"i": cluster_list[curr_distance_idx].cluster_centroid["i"],
                               "j": cluster_list[curr_distance_idx].cluster_centroid["j"]}

            self.idx += 1

            # DEBUG

            # print("______________________________________  \n")
            # print("      THIS IS NOT CLOSEST FRONTIER      \n")
            # print("|   ", cluster_list[curr_distance_idx].cluster_id, "      |   [",
            #       [cluster_list[curr_distance_idx].cluster_centroid["j"],
            #        cluster_list[curr_distance_idx].cluster_centroid["i"]], "]    |   ",
            #       distance_from_centroid[curr_distance_idx], "    |   ",
            #       [robot_position_pix["j"], robot_position_pix["i"]], "      |  \n")
            # print("______________________________________  \n")

            # END OF DEBUG

        else:

            min_distance = distance_from_centroid_sorted[0]

            min_distance_idx = distance_from_centroid.index(min_distance)

            goal_coords_pix = {"i": cluster_list[min_distance_idx].cluster_centroid["i"],
                               "j": cluster_list[min_distance_idx].cluster_centroid["j"]}

            self.idx = 1  # zeroing the counter
            # DEBUG

            # print("______________________________________  \n")
            # print("      THIS IS CLOSEST FRONTIER          \n")
            # print("|   ", cluster_list[min_distance_idx].cluster_id, "      |   [",
            #       [cluster_list[min_distance_idx].cluster_centroid["j"],
            #        cluster_list[min_distance_idx].cluster_centroid["i"]], "]    |   ",
            #       distance_from_centroid[min_distance_idx], "    |   ",
            #       [robot_position_pix["j"], robot_position_pix["i"]], "      |  \n")
            # print("______________________________________  \n")

            # END OF DEBUG

        goal_coords_m = {"x": goal_coords_pix["i"]*map_resolution,
                         "y": goal_coords_pix["j"]*map_resolution}

        print("This is what comes out of DFD in [m]: \n", goal_coords_m)

        # DEBUG
        # raw_costmap_data_numpy_reshape_copy = copy.deepcopy(raw_costmap_data_numpy_reshape)
        # raw_costmap_data_numpy_reshape_copy = raw_costmap_data_numpy_reshape_copy.astype(np.uint8)
        # raw_costmap_data_numpy_reshape_copy[cluster_list[min_distance_idx].cluster_centroid["i"]][
        #     cluster_list[min_distance_idx].cluster_centroid["j"]] = 175
        #
        # name = "Goal: "+str(cluster_list[min_distance_idx].cluster_centroid["i"])+" "\
        #            + str(cluster_list[min_distance_idx].cluster_centroid["j"])
        #
        # cv2.namedWindow(name, cv2.WINDOW_NORMAL)  # new window, named 'win_name'
        # cv2.imshow(name, raw_costmap_data_numpy_reshape_copy)  # show image on window 'win_name' made of numpy.ndarray
        # cv2.resizeWindow(name, 1600, 900)  # resizing window on my resolution
        #
        # cv2.waitKey(0)  # wait for key pressing
        # cv2.destroyAllWindows()  # close all windows

        # END OF DEBUG

        return goal_coords_m


class TurtleBotSlamExplorer:

    def __init__(self):

        self.rate = rospy.Rate(5)  # rate of message sending is 10 Hz

        # Actionlib client definition #
        # move base is name of topic of the package, publishing the message on that topic allows you to move robot
        # in a desired position.
        # SimpleActionClient publishes messages on /move_base topic with format: MoveBaseAction
        self.action_client = actionlib.SimpleActionClient('/move_base', MoveBaseAction)
        self.action_client.wait_for_server()

        # tf2 package definition for translating and rotating frames
        self.tf2_broadcaster = tf2_ros.TransformBroadcaster()  # broadcasting new frames to the network
        self.tf2_buffer = tf2_ros.Buffer()  # stores all frames
        self.tf2_listener = tf2_ros.TransformListener(self.tf2_buffer)  # listens for new frames and calculating
        # translation and rotation between them

        self.status_buffer = np.zeros((10,), dtype=int)                 # stores last 10 statuses of the goal
        self.status_buffer_timestamp = [rospy.Duration(0.0), rospy.Duration(0.0), rospy.Duration(0.0), rospy.Duration(0.0),
                                        rospy.Duration(0.0), rospy.Duration(0.0), rospy.Duration(0.0), rospy.Duration(0.0),
                                        rospy.Duration(0.0), rospy.Duration(0.0)]   # stores timestamps of last 10 statuses

        self.first_goal: bool = True  # flag, which indicates, that robot goes
        # to it's first goal

        self.min_vel = 0.18  # [m/s] minimal speed of TurtleBot
        # set up in base_local_planner_params.yamls

        self.t_diff_goals = 0.1         # [s] due to goal slippering - required time difference between sending goals

        self.state = 0                  # state enumerator for state machine in self.explore()

    # FUNCTION, WHICH MAKES NEW FRAME BY TRANSFORMING FROM OLD AND SENDS IT OUT TO BUFFER
    def add_new_transformed_frame(self, parent_frame_id: str, child_frame_id: str, translation: dict, rotation: dict):

        new_transform_stamped = TransformStamped()  # initialise new transform object
        new_transform_stamped.header.stamp = rospy.Time.now()  # stamping it
        new_transform_stamped.header.frame_id = parent_frame_id  # adding source frame
        new_transform_stamped.child_frame_id = child_frame_id  # adding child frame

        # definition of new frame's rotation and translation parameters
        new_transform = Transform(
            translation=Vector3(
                x=translation["x"],
                y=translation["y"],
                z=translation["z"]),
            rotation=Quaternion(
                x=rotation["x"],
                y=rotation["y"],
                z=rotation["z"],
                w=rotation["w"]  # "1" - to save the orientation of new frame
            )

        )

        new_transform_stamped.transform = new_transform  # adding of transformation to object

        # sending out the transformed frame
        self.tf2_broadcaster.sendTransform(new_transform_stamped)

        return child_frame_id

    # FUNCTION SETS TWO NEW FRAMES ('CELL(0,0)' FRAME <- /map FRAME; 'GOAL' FRAME <- 'CELL(0,0)' FRAME) AND CALCULATES
    # TRANSFORMATION FROM ORIGIN /map FRAME TO 'GOAL' FRAME, THEN SEND TRANSFORMATION BETWEEN THEM
    # (WHICH IS EQUIVALENT TO MOVING THE MAP FRAME TO (0,0),
    # that's why it's called set_zeroed_frame_and_transform)
    def set_zeroed_map_frame_and_transform(self, raw_map: tuple, goal_coords: dict, parent_frame: str,
                                           child_frame: str):

        # --------------------------------------------------------------------------------------------------

        ################################
        # Transformation of the frames #
        ################################

        # (*) GETTING THE TRANSFORM FROM /map FRAME ORIGIN TO THE CELL(0,0) IN THE MAP (LOWER LEFT CORNER) #

        self.add_new_transformed_frame(parent_frame, "lower left corner",
                                       # x coordinates in [m] of cell(0,0) on the /map frame
                                       {"x": raw_map.info.origin.position.x,
                                        # y coordinates in [m] of cell(0,0) on the /map frame
                                        "y": raw_map.info.origin.position.y,
                                        "z": 0},
                                       {"x": 0, "y": 0, "z": 0, "w": 1})

        # (*) GETTING THE TRANSFORM FROM lower left corner FRAME ORIGIN TO THE goal coordinates #

        self.add_new_transformed_frame("lower left corner", child_frame,
                                       {"x": goal_coords["x"],
                                        "y": goal_coords["y"], "z": 0},
                                       {"x": 0, "y": 0, "z": 0, "w": 1})

        #######################################
        # End of Transformation of the frames #
        #######################################

        # --------------------------------------------------------------------------------------------------

        ######################################################################
        # Getting the translation between original /map frame and goal frame #
        ######################################################################

        # Getting 'map' and 'goal coordinates' frames from buffer and calculating transformation between them

        try:
            resulting_tranformation = self.tf2_buffer.lookup_transform('map',
                                                                       'goal coordinates',
                                                                       rospy.Time())
            transform_errors = False

            return resulting_tranformation, transform_errors

        except (tf2_ros.LookupException,
                tf2_ros.ConnectivityException,
                tf2_ros.ExtrapolationException):

            rospy.loginfo('ERROR: Lookup transform between frames!')
            transform_errors = True

            return None, transform_errors

        #############################################################################
        # End of Getting the translation between original /map frame and goal frame #
        #############################################################################

    # FOR NOW THIS IS NAIVE FRONTIER DETECTING ALGORITHM, RANDOMLY CHOSING UNKNOWN CELLS ON THE MAP
    def naive_frontier_detection(self, raw_map_data_numpy_reshape: np.ndarray,
                           raw_costmap_data_numpy_reshape: np.ndarray) -> dict:

        # goal is to send turtlebot to the cell of the map with coordinates [raw_map_numpy["x"], -//-["y"]]

        # searching of unknown cells in map with low cost of going there (doesn't have walls or angles around it)
        frontier_indices = np.where((raw_map_data_numpy_reshape == -1) &
                                    (raw_costmap_data_numpy_reshape < 20))

        if not frontier_indices:
            rospy.loginfo('ERROR: Frontier finding!')

        rnd_i = randint(0, np.shape(frontier_indices)[1] - 1)  # random choose from all rows and columns in
        # raw_map_..._reshape, which contains -1

        goal_coords = {"x": frontier_indices[1][rnd_i], "y": frontier_indices[0][rnd_i]}

        return goal_coords

    # get pose of robot in odom frame
    def get_pose_of_robot(self, raw_map_origin_pos, map_resolution):

        raw_odom_message = rospy.wait_for_message('/odom', Odometry)

        # vector of the robot position in odometry frame:
        x_od = {"x": raw_odom_message.pose.pose.position.x,
                "y": raw_odom_message.pose.pose.position.y}

        # DEBUG
        print("This is coordinates of robot in odom frame:\n", {"x": raw_odom_message.pose.pose.position.x,
                                                                "y": raw_odom_message.pose.pose.position.y})
        # END OF DEBUG

        # searching for transformation between "odom" frame and "map" frame
        try:
            tf_odom2map = self.tf2_buffer.lookup_transform("map",
                                                           "odom",
                                                           rospy.Time())
            # DEBUG
            print("This is transformation in map frame:\n", {"x": tf_odom2map.transform.translation.x,
                                                             "y": tf_odom2map.transform.translation.y})
            # END OF DEBUG

        except (tf2_ros.LookupException,
                tf2_ros.ConnectivityException,
                tf2_ros.ExtrapolationException):

            rospy.loginfo('ERROR: Lookup transform between frames while catching ROBOT position!')

        # if transformation was found -> OK, else assume that /map and /odom frames are the same
        if tf_odom2map:
            # vector of the translation of odom to map
            x_map2od = {"x": tf_odom2map.transform.translation.x,
                        "y": tf_odom2map.transform.translation.y}
        else:
            # vector of the translation of odom to map
            x_map2od = {"x": 0,
                        "y": 0}

        # vector of position of origin [0, 0] in the /map frame
        x_map2or = raw_map_origin_pos

        # finding vector of position of robot [m] in origin frame ( == pos of robot in or frame) by vector summation
        x_or_m = {"x": x_od["x"] + x_map2od["x"] - x_map2or["x"],
                  "y": x_od["y"] + x_map2od["y"] - x_map2or["y"]}

        # finding vector of position of robot [pix]
        x_or_pix = {"i": int(x_or_m["x"] / map_resolution),
                    "j": int(x_or_m["y"] / map_resolution)}

        # DEBUG
        print("This is coordinates of robot in !ORIGIN (lower_left_corner) frame [m]:\n", x_or_m)
        # END OF DEBUG

        return x_or_pix, x_or_m

    # THIS IS MAIN FUNCTION OF CLASS, IT IMPLEMENTS AUTONOMOUS EXPLORATION
    def explore(self):

        while not rospy.is_shutdown():

            # "INIT" STATE
            if self.state == 0:

                print("_|___________________________________|_")
                print(" |     This is state: ", self.state, "            | ")
                print("_|___________________________________|_")

                # args: min frontier size is 0.2 [m^2], 0.9 - lower percentage cutoff is 90 [%]
                frontier_detector = DFDdetectorClass(0.05, 0.9)       # init frontier detector class
                raw_map = rospy.wait_for_message('/map', OccupancyGrid)  # get map with metadata
                raw_map_data_numpy = np.asarray(raw_map.data)  # 1d map -> np.ndarray
                previous_map_reshape = raw_map_data_numpy.reshape((raw_map.info.height,  # reshaping 1d np.ndarray
                                                                   raw_map.info.width))  # to 2d with right size
                # Occupancy grid explanation: -1 - unknown, 100 - Occupied, 0 - not occupied #
                self.state = 1             # goes to the next state

            # "SETTING UP GOAL IN ARRAY FRAME" STATE
            if self.state == 1:

                print("_|___________________________________|_")
                print(" |     This is state: ", self.state, "            | ")
                print("_|___________________________________|_")

                # FETCHING MAP #

                raw_map = rospy.wait_for_message('/map', OccupancyGrid)  # get map with metadata
                raw_map_data_numpy = np.asarray(raw_map.data)  # 1d map -> np.ndarray

                raw_map_data_numpy_reshape = raw_map_data_numpy.reshape((raw_map.info.height,  # reshaping 1d np.ndarray
                                                                         raw_map.info.width))  # to 2d with right size
                # Occupancy grid explanation: -1 - unknown, 100 - Occupied, 0 - not occupied #

                # get position of origin of the map in the /map frame
                raw_map_origin_pos = {"x": raw_map.info.origin.position.x,
                                      "y": raw_map.info.origin.position.y}

                # get raw map resolution [m/cell]
                raw_map_resolution = raw_map.info.resolution

                # costmap explanation: -1 - unknown, 0 -> 100 - probability of occupancy

                # (!) FRONTIER DETECTION PART

                # # * DFD:

                # get pose of robot in [pixels] and [m]
                pose_of_robot_pix, pose_of_robot_m = self.get_pose_of_robot(raw_map_origin_pos, raw_map_resolution)

                # DEBUG

                # self.add_new_transformed_frame("lower left corner", "fetched robot position",
                #                                # x coordinates in [m] of cell(0,0) on the /map frame
                #                                {"x": pose_of_robot_m["x"],
                #                                 # y coordinates in [m] of cell(0,0) on the /map frame
                #                                 "y": pose_of_robot_m["y"],
                #                                 "z": 0},
                #                                {"x": 0, "y": 0, "z": 0, "w": 1})

                # END OF DEBUG

                # get current coordinates of goal in [m]
                goal_coords = frontier_detector.frontier_detection_DFD(raw_map_data_numpy_reshape,
                                                                       pose_of_robot_pix,
                                                                       raw_map.info.resolution,
                                                                       previous_map_reshape)
                previous_map_reshape = raw_map_data_numpy_reshape

                self.state = 2      # going to the next state

            # "SETTING UP THE GOAL IN THE MAP FRAME" STATE
            if self.state == 2:

                print("_|___________________________________|_")
                print(" |     This is state: ", self.state, "            | ")
                print("_|___________________________________|_")

                # calculating the aproximation of travel time to the goal
                straight_distance = sqrt((goal_coords["x"] - pose_of_robot_m["x"]) ** 2 +
                                         (goal_coords["y"] - pose_of_robot_m["y"]) ** 2)

                approximate_travel_time = straight_distance / self.min_vel  # [s]
                if approximate_travel_time < 5:
                    approximate_travel_time = 5

                print('(*) This is goal coords:', goal_coords, "\n")

                # SETTING THE FRAMES AND RETURNING CALCULATED TRANSFORMATION

                resulting_transformation, transform_errors = self.set_zeroed_map_frame_and_transform(raw_map,
                                                                                                     goal_coords,
                                                                                                     "map",
                                                                                                     "goal coordinates")

                # checking if tf server made transformation
                if resulting_transformation:

                    self.state = 3          # going to the next state

                else:

                    pass                    # wait for the transformation
                    # self.state = 1          # going to the "SETTING UP GOAL IN ARRAY FRAME" state

            # "SENDING GOAL" STATE
            if self.state == 3:

                print("_|___________________________________|_")
                print(" |     This is state: ", self.state, "            | ")
                print("_|___________________________________|_")

                goal = MoveBaseGoal()
                goal.target_pose.header.frame_id = "map"
                goal.target_pose.header.stamp = rospy.Time.now()
                goal.target_pose.pose.position.x = resulting_transformation.transform.translation.x
                goal.target_pose.pose.position.y = resulting_transformation.transform.translation.y
                goal.target_pose.pose.orientation.w = 1.0

                # Send goal with timeout: args: (_, timeout for robot to move to the goal, timeout for robot to
                # accept the goal)
                self.action_client.send_goal_and_wait(goal, rospy.Duration(2 * approximate_travel_time),
                                                      rospy.Duration(0.0))

                self.state = 1  # go to the "SETTING UP GOAL IN ARRAY FRAME" state

            # REFRESHING THE GOAL STATUS BUFFER
            self.status_buffer_timestamp.append(rospy.Time.now())  # append last timestmp
            self.status_buffer = np.append(self.status_buffer,
                                           self.action_client.get_state())  # append last status
            # to the buffer
            self.status_buffer_timestamp.remove(self.status_buffer_timestamp[0])  # delete the oldest
            self.status_buffer = np.delete(self.status_buffer, 0)  # delete the oldest

            print("(*) This is last 10 goal statuses: ", self.status_buffer, "\n")
            print("(*) This is timestamps of last 10 goal statuses: ", self.status_buffer_timestamp, "\n")


def main():
    rospy.init_node('slam_explorer_n')
    slam_explorer = TurtleBotSlamExplorer()
    slam_explorer.explore()


if __name__ == '__main__':
    try:
        main()
    except rospy.ROSInterruptException:
        pass
